{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGkBjAh15oCp"
   },
   "source": [
    "## 1.2 Classifier definition\n",
    "\n",
    "Let's define a basic Classifier class. It will be used in both the normal and the adversarial training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the signal/BKG DFs and split into test/train sets   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkg = pd.read_csv('/nfs/dust/cms/user/amohamed/susy-desy/CMGSamples/FR_forMVA_nosplit_resTop/csvs/MultiClass_background.csv')\n",
    "df_sig = pd.read_csv('/nfs/dust/cms/user/amohamed/susy-desy/CMGSamples/FR_forMVA_nosplit_resTop/csvs/MultiClass_signal.csv')\n",
    "\n",
    "df_sig.loc[:,'Y'] = 1\n",
    "df_bkg.loc[:,'Y'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      "0    2516878\n",
      "1     611306\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "_df_all = pd.DataFrame()\n",
    "_df_all = pd.concat([df_sig,df_bkg],sort=False)\n",
    "del df_sig; del df_bkg\n",
    "print (_df_all.groupby(['Y']).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DF, test_DF = train_test_split(_df_all, train_size=0.6, test_size=0.4, shuffle=True, random_state=0)\n",
    "features = ['MET', 'MT', 'Jet2_pt','Jet1_pt', 'nLep', 'Lep_pt', 'Selected', 'nVeto', 'LT', 'HT', 'nBCleaned_TOTAL','nTop_Total_Combined', 'nJets30Clean',\"Lep_relIso\",\"Lep_miniIso\",\"iso_pt\",\"iso_MT2\"]\n",
    "\n",
    "S_train = train_DF[features].copy()\n",
    "S_test  = test_DF[features].copy()\n",
    "Y_train = train_DF['Y'].copy()\n",
    "Y_test  = test_DF['Y'].copy()\n",
    "Z_train = train_DF['dPhi'].copy()\n",
    "Z_test  = test_DF['dPhi'].copy()\n",
    "\n",
    "del train_DF ; del test_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# allocate all the dfs to the proper device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_train, S_test, Y_train, Y_test, Z_train, Z_test = [\n",
    "    torch.tensor(x).to(device)\n",
    "    for x in [S_train.values, S_test.values, Y_train.values, Y_test.values, Z_train.values, Z_test.values]\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "indx = torch.randint(0, S_train.shape[0], size=(32, ))\n",
    "indx.shape\n",
    "S_train[indx]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_test = torch.utils.data.TensorDataset(X_test, y_test, z_test)\n",
    "loader_test =  torch.utils.data.DataLoader(dataset_test, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bW1F7cd1upQ6"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic classifier class\n",
    "    \n",
    "    Args:\n",
    "        width (int): number of nodes in each layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, width, n_inputs=2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.width = width\n",
    "    \n",
    "        # input layer\n",
    "        self.input = nn.Linear(n_inputs, width)\n",
    "    \n",
    "        # hidden layers\n",
    "        self.h1 = nn.Linear(width, width)\n",
    "        self.h2 = nn.Linear(width, width)\n",
    "    \n",
    "        # output layer\n",
    "        self.output = nn.Linear(width, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        # input layer\n",
    "        x = F.relu(self.input(x))\n",
    "    \n",
    "        # hidden layers\n",
    "        x = F.relu(self.h1(x))\n",
    "        x = F.relu(self.h2(x))\n",
    "        \n",
    "        # output layer\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5slQhbEy515g"
   },
   "source": [
    "### Adversary definition\n",
    "\n",
    "In this simple example the adversary is a regression NN. It is used to predict the protected parameter Z from the classifier output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvBJeyd0-NHT"
   },
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic regressor class. Can (and will) be used as the adversary in the\n",
    "    training of the classifier.\n",
    "    \n",
    "    Args:\n",
    "        width (int): number of nodes in each layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, width):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.width = width\n",
    "    \n",
    "        # input layer\n",
    "        self.input = nn.Linear(1, width)\n",
    "    \n",
    "        # hidden layers\n",
    "        self.h1 = nn.Linear(width, width)\n",
    "        self.h2 = nn.Linear(width, width)\n",
    "    \n",
    "        # output layer\n",
    "        self.output = nn.Linear(width, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        # input layer\n",
    "        x = F.relu(self.input(x))\n",
    "    \n",
    "        # hidden layers\n",
    "        x = F.relu(self.h1(x))\n",
    "        x = F.relu(self.h2(x))\n",
    "        \n",
    "        # output layer\n",
    "        x = self.output(x)\n",
    "    \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8DCFaewVO9T"
   },
   "source": [
    "### Classifier training with the adversary\n",
    "\n",
    "Train the classifier adversarially. Make sure you understand the code in this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "colab_type": "code",
    "id": "In-VufRz5x5c",
    "outputId": "82dc6465-ebe2-489b-e795-7b5ba309afa4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b85156a168b41168f24dec89f516203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ed439f3b4a4776a9e971a1b32858ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=291), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 612.00 MiB (GPU 0; 15.90 GiB total capacity; 5.48 GiB already allocated; 316.88 MiB free; 15.36 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fa1a2eaacdf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mclf_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;31m#evaluate_classifier(clf_toys_adv, generate_toys)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fa1a2eaacdf0>\u001b[0m in \u001b[0;36madversarial_training\u001b[0;34m(n_inputs, epochs, nbatch)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mX_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mY_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0moutput_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mclf_losses_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/dust/cms/user/amohamed/anaconda3/envs/hepML/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-71bbf204598f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# hidden layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/dust/cms/user/amohamed/anaconda3/envs/hepML/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/dust/cms/user/amohamed/anaconda3/envs/hepML/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/dust/cms/user/amohamed/anaconda3/envs/hepML/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 612.00 MiB (GPU 0; 15.90 GiB total capacity; 5.48 GiB already allocated; 316.88 MiB free; 15.36 MiB cached)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def adversarial_training(n_inputs,epochs=200, nbatch = 291):\n",
    "    \n",
    "    # create the classifier and the adversary networks\n",
    "    clf = Classifier(128, n_inputs=n_inputs).to(device)\n",
    "    adv = Regressor(50).to(device)\n",
    "\n",
    "    # training settings\n",
    "    learning_rate = 0.001\n",
    "    lam = 10.0 # lambda tradeoff parameter\n",
    "\n",
    "    # choose the criterions\n",
    "    clf_criterion = nn.BCELoss()\n",
    "    adv_criterion = nn.MSELoss()\n",
    "\n",
    "    # create optimisers (larger learning rate for the adversary )\n",
    "    clf_optimiser = torch.optim.Adam(clf.parameters(), lr=learning_rate)\n",
    "    adv_optimiser = torch.optim.Adam(adv.parameters(), lr=5*learning_rate)\n",
    "\n",
    "    # keep track of the losses\n",
    "    clf_losses = []\n",
    "    adv_losses = []\n",
    "    clf_losses_test = []\n",
    "    adv_losses_test = []\n",
    "    \n",
    "    # training loop\n",
    "    for i in tqdm(range(epochs)):\n",
    "        for j in tqdm(range(nbatch)):\n",
    "            # create the data\n",
    "            indx = torch.randint(0, S_train.shape[0], size=(4096, ))\n",
    "            #X_batch, y_batch, z_batch = X_train[indx], y_train[indx], z_train[indx]\n",
    "            X, Y, Z = S_train[indx], Y_train[indx], Z_train[indx]\n",
    "            X = torch.as_tensor(X, dtype=torch.float).to(device)\n",
    "            Y = torch.as_tensor(Y.reshape(-1, 1), dtype=torch.float).to(device)\n",
    "            Z = torch.as_tensor(Z.reshape(-1, 1), dtype=torch.float).to(device)\n",
    "\n",
    "            ##############################\n",
    "            # Update the adversary network\n",
    "            # (several updtes to keep up with\n",
    "            # the changes in the classifier)\n",
    "            ##############################\n",
    "\n",
    "            M = 5\n",
    "            for _ in range(M):\n",
    "                # make the adversary loss\n",
    "                clf_output = clf(X)\n",
    "                adv_output = adv(clf_output)\n",
    "                adv_loss = adv_criterion(adv_output, Z)\n",
    "\n",
    "                # backprop: adapt the adversary to the classifier (only update the adversary weights)\n",
    "                adv.zero_grad()\n",
    "                adv_loss.backward()\n",
    "                adv_optimiser.step()\n",
    "\n",
    "            adv_losses.append(adv_loss.to('cpu').detach().numpy())\n",
    "\n",
    "            ##############################\n",
    "            # Update the classifier network\n",
    "            ##############################\n",
    "\n",
    "            # forward pass\n",
    "            clf_output = clf(X)\n",
    "            adv_output = adv(clf_output)\n",
    "\n",
    "            # make the losses: both the classifier and the adversary loss\n",
    "            # combined loss: note the minus sign!\n",
    "            # (when updating the classifier, the goal is to confuse the adversary)\n",
    "            clf_loss = clf_criterion(clf_output, Y)\n",
    "            adv_loss = adv_criterion(adv_output, Z)\n",
    "            comb_loss = clf_loss - lam * adv_loss\n",
    "\n",
    "            # backprop the classifier: update only the classifier weights (keep adversary intact)\n",
    "            clf.zero_grad()\n",
    "            comb_loss.backward()\n",
    "            clf_optimiser.step()\n",
    "\n",
    "            clf_losses.append(clf_loss.to('cpu').detach().numpy())\n",
    "\n",
    "        #######################\n",
    "        # store the test losses\n",
    "        #######################\n",
    "        X_t, Y_t = S_test , Y_test\n",
    "        X_t = torch.as_tensor(X_t, dtype=torch.float).to(device)\n",
    "        Y_t = torch.as_tensor(Y_t.reshape(-1, 1), dtype=torch.float).to(device)\n",
    "        output_test = clf(X_t)\n",
    "        loss_test = clf_criterion(output_test, Y_t)\n",
    "        clf_losses_test.append(loss_test.to('cpu').detach().numpy())\n",
    "    \n",
    "    print('Done with training')\n",
    "\n",
    "    fig, ax = plt.subplots(2, sharex=True)\n",
    "    ax[0].plot(range(len(clf_losses)), clf_losses, label='train loss')\n",
    "    ax[0].plot(range(len(clf_losses_test)), clf_losses_test, label='test loss')\n",
    "    ax[0].set_ylabel('Classifier loss')\n",
    "    ax[0].legend(loc='best')\n",
    "    ax[1].plot(range(len(adv_losses)), adv_losses, color='k')\n",
    "    ax[1].set_ylabel('Adversary loss')\n",
    "    ax[1].set_xlabel('Training step')\n",
    "    plt.show()\n",
    "    \n",
    "    return clf\n",
    "\n",
    "clf_adv = adversarial_training(S_train.shape[1], epochs=10)\n",
    "#evaluate_classifier(clf_toys_adv, generate_toys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "heDz0bAuX_xX"
   },
   "source": [
    "# Tasks for Farouk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what you have to do is to run over 100 epochs\n",
    "1- add semilar loop to train the classifier only to be compared with the adversary <br>\n",
    "2- scan range of $\\lambda$ value with adverserial from $[0.5,10]$<br>\n",
    "3- check few points for the same lambda and check the stability of it<br> \n",
    "4- for each batch calculate the losses of test/train sample and at the end of the epoch compare the avarage of both<br>\n",
    "5- add plotting code for ROC and classifier output as well<br>\n",
    "6- add code to calculate the ratios $\\frac{A/B}{C/D}$<br>\n",
    "7- clean up you code reqularly and keep only the lines where you need to use otherwise remove<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IndependenceSeminar.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
